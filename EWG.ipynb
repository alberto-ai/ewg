{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFztTJm5o92V"
   },
   "source": [
    "# Scrapping EWG Tap Water Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2Sdbnhmo92W"
   },
   "source": [
    "Since 2010, water utilities' testing has found pollutants in Americans' tap water, according to an EWG drinking water quality analysis of 30 million state water records. The EWG Tap Water database can be consulted in their [web](https://www.ewg.org/tapwater/).\n",
    "\n",
    "It loooks like an interesting database so in this Python notebook I implement a process to scrap the database so I can be exported as CSV to further exploit this information. \n",
    "\n",
    "The project also makes use of a ZIP database obtained from [simplemaps.com](https://simplemaps.com/data/us-zips) which is used as the baseline to query all potential ZIP codes.\n",
    "\n",
    "**NOTE** this project is purely for educational purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6d0Jv6Cho92X"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFgnqMgbo92X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import progressbar\n",
    "import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBE4T7Nho92Z"
   },
   "source": [
    "### Read postal codes database\n",
    "Reference ZIP database obtained from [simplemaps.com](https://simplemaps.com/data/us-zips). The database contains the following fields:\n",
    "- `zip`: The 5-digit zip code assigned by the U.S. Post Office.\n",
    "- `lat`: \tThe latitude of the zip code (learn more).\n",
    "- `lng`: \tThe longitude of the zip code (learn more).\n",
    "- `city`: \tThe official USPS city name.\n",
    "- `state_id`: \tThe official USPS state abbreviation.\n",
    "- `state_name`: \tThe state's name. Blank string for military zip codes where state_id is AA, AE, or AP.\n",
    "- `zcta`: \tTRUE if the zip code is a Zip Code Tabulation area (learn more).\n",
    "- `parent_zcta`: \tThe ZCTA that contains this zip code. Only exists if zcta is FALSE. Useful for making inferences about a zip codes that is a point from the ZCTA that contains it.\n",
    "- `population`: \tAn estimate of the zip code's population. Only exists if zcta is TRUE.\n",
    "- `county_fips`: \tThe primary county that contains the zip code in the FIPS format.\n",
    "- `county_name`: \tThe name of the county_fips.\n",
    "- `county_weight`: \tThe percentage of the zip code that is within the county (by population).\n",
    "- `all_county_weights`: \tA JSON dictionary listing all counties and weights associated with the zip code.\n",
    "- `imprecise`: \tTRUE if the lat/lng has been geolocated using the city (rare).\n",
    "- `military`: \tTRUE if the zip code is used by the US Military (lat/lng not available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySeKF1kWo92a"
   },
   "outputs": [],
   "source": [
    "# when reading the dataframe I specify that zip code is a string so the Os at the beginning of the zip code are not lost\n",
    "POSTAL_CODES_PATH = './postalcodes.csv'\n",
    "zip_df = pd.read_csv(POSTAL_CODES_PATH, dtype={'zip': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4OFrfIoNo92c"
   },
   "source": [
    "#### Check missing information\n",
    "Looking at the data in the dataframe we can see that we have no missing information regarding the features: `zip`, `city`, `state_id`, `imprecise` and `military`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKPZb7Muo92d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postal codes dataframe shape:  (41682, 14)\n",
      "Missing information in % rounded to 2 decimals\n",
      "zip                   0.00\n",
      "lat                   0.01\n",
      "lng                   0.01\n",
      "city                  0.00\n",
      "state_id              0.00\n",
      "state_name            0.01\n",
      "zcta                  0.00\n",
      "parent_zcta           0.81\n",
      "population            0.21\n",
      "county_fips           0.21\n",
      "county_name           0.21\n",
      "all_county_weights    0.21\n",
      "imprecise             0.00\n",
      "military              0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "print('Postal codes dataframe shape: ', zip_df.shape)\n",
    "print('Missing information in % rounded to 2 decimals')\n",
    "pp.pprint((zip_df.isna().sum() / zip_df.shape[0]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejshVQmxo92h"
   },
   "source": [
    "#### Remove unused columns\n",
    "Most of the fields in the database will not be used therefore can be removed from the dataframe. Some of them because have not any use for the EWG Tap Water database scrapping and others such as `county_name` because there are too zip codes without such information, more than 20%. \n",
    "\n",
    "```python\n",
    "unused_fields = ['zcta', 'parent_zcta', 'county_fips', 'county_name', 'all_county_weights', 'imprecise', 'military']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9psxW52o92i"
   },
   "outputs": [],
   "source": [
    "unused_fields = ['zcta', 'parent_zcta', 'county_fips', 'county_name', 'all_county_weights', 'imprecise', 'military']\n",
    "zip_df.drop(unused_fields, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ru01AgTQo92k"
   },
   "source": [
    "#### Remaining structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALtGKtY_o92k"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00501</td>\n",
       "      <td>40.8133</td>\n",
       "      <td>-73.0476</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00544</td>\n",
       "      <td>40.8133</td>\n",
       "      <td>-73.0476</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00601</td>\n",
       "      <td>18.1800</td>\n",
       "      <td>-66.7522</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>18570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00602</td>\n",
       "      <td>18.3607</td>\n",
       "      <td>-67.1752</td>\n",
       "      <td>Aguada</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00603</td>\n",
       "      <td>18.4544</td>\n",
       "      <td>-67.1220</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>54689.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zip      lat      lng        city state_id   state_name  population\n",
       "0  00501  40.8133 -73.0476  Holtsville       NY     New York         NaN\n",
       "1  00544  40.8133 -73.0476  Holtsville       NY     New York         NaN\n",
       "2  00601  18.1800 -66.7522    Adjuntas       PR  Puerto Rico     18570.0\n",
       "3  00602  18.3607 -67.1752      Aguada       PR  Puerto Rico     41520.0\n",
       "4  00603  18.4544 -67.1220   Aguadilla       PR  Puerto Rico     54689.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASls3tfAo92n"
   },
   "source": [
    "#### State name correction\n",
    "Although the `state_id` is available for all zip codes the `state_name` is missing for some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2pT_E6lo92p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['NY', 'PR', 'VI', 'MA', 'RI', 'NH', 'ME', 'VT', 'CT', 'NJ', 'AE',\n",
      "       'PA', 'DE', 'DC', 'VA', 'MD', 'WV', 'NC', 'SC', 'GA', 'FL', 'AA',\n",
      "       'AL', 'TN', 'MS', 'KY', 'OH', 'IN', 'MI', 'IA', 'WI', 'MN', 'SD',\n",
      "       'ND', 'MT', 'IL', 'MO', 'KS', 'NE', 'LA', 'AR', 'OK', 'TX', 'CO',\n",
      "       'WY', 'ID', 'UT', 'AZ', 'NM', 'NV', 'CA', 'AP', 'HI', 'AS', 'GU',\n",
      "       'PW', 'FM', 'MP', 'MH', 'OR', 'WA', 'AK'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(zip_df.state_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfFiJePfo92r"
   },
   "source": [
    "By creating a dictionary of `state_id` and `state_name` we can see what are the missing states. Which basically are:\n",
    "- Armed Forces Africa, Canada, Europe, Middle East = AE\n",
    "- Armed Forces Americas (except Canada) = AA\n",
    "- Armed Forces Pacific = AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpbiOt7jo92s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'AA': nan,\n",
      "    'AE': nan,\n",
      "    'AK': 'Alaska',\n",
      "    'AL': 'Alabama',\n",
      "    'AP': nan,\n",
      "    'AR': 'Arkansas',\n",
      "    'AS': 'American Samoa',\n",
      "    'AZ': 'Arizona',\n",
      "    'CA': 'California',\n",
      "    'CO': 'Colorado',\n",
      "    'CT': 'Connecticut',\n",
      "    'DC': 'District of Columbia',\n",
      "    'DE': 'Delaware',\n",
      "    'FL': 'Florida',\n",
      "    'FM': 'Federated States of Micronesia',\n",
      "    'GA': 'Georgia',\n",
      "    'GU': 'Guam',\n",
      "    'HI': 'Hawaii',\n",
      "    'IA': 'Iowa',\n",
      "    'ID': 'Idaho',\n",
      "    'IL': 'Illinois',\n",
      "    'IN': 'Indiana',\n",
      "    'KS': 'Kansas',\n",
      "    'KY': 'Kentucky',\n",
      "    'LA': 'Louisiana',\n",
      "    'MA': 'Massachusetts',\n",
      "    'MD': 'Maryland',\n",
      "    'ME': 'Maine',\n",
      "    'MH': 'Marshall Islands',\n",
      "    'MI': 'Michigan',\n",
      "    'MN': 'Minnesota',\n",
      "    'MO': 'Missouri',\n",
      "    'MP': 'Northern Mariana Islands',\n",
      "    'MS': 'Mississippi',\n",
      "    'MT': 'Montana',\n",
      "    'NC': 'North Carolina',\n",
      "    'ND': 'North Dakota',\n",
      "    'NE': 'Nebraska',\n",
      "    'NH': 'New Hampshire',\n",
      "    'NJ': 'New Jersey',\n",
      "    'NM': 'New Mexico',\n",
      "    'NV': 'Nevada',\n",
      "    'NY': 'New York',\n",
      "    'OH': 'Ohio',\n",
      "    'OK': 'Oklahoma',\n",
      "    'OR': 'Oregon',\n",
      "    'PA': 'Pennsylvania',\n",
      "    'PR': 'Puerto Rico',\n",
      "    'PW': 'Palau',\n",
      "    'RI': 'Rhode Island',\n",
      "    'SC': 'South Carolina',\n",
      "    'SD': 'South Dakota',\n",
      "    'TN': 'Tennessee',\n",
      "    'TX': 'Texas',\n",
      "    'UT': 'Utah',\n",
      "    'VA': 'Virginia',\n",
      "    'VI': 'Virgin Islands',\n",
      "    'VT': 'Vermont',\n",
      "    'WA': 'Washington',\n",
      "    'WI': 'Wisconsin',\n",
      "    'WV': 'West Virginia',\n",
      "    'WY': 'Wyoming'}\n"
     ]
    }
   ],
   "source": [
    "states_dictionary = dict(zip(zip_df.state_id,zip_df.state_name))\n",
    "pp.pprint(states_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzTB5Cppo92u"
   },
   "source": [
    "Let's fill the missing `state_name` using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lj_0-QhAo92v"
   },
   "outputs": [],
   "source": [
    "missing_state = {\n",
    "    'AE': 'Armed Forces Africa, Canada, Europe, Middle East', \n",
    "    'AA': 'Armed Forces Americas (except Canada)',\n",
    "    'AP': 'Armed Forces Pacific'\n",
    "}\n",
    "\n",
    "zip_df['state_name'] = zip_df['state_name'].fillna(zip_df['state_id'].map(missing_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xo38NdgZo92z"
   },
   "source": [
    "We can check that the problem with `state_name` is solved. \n",
    "There are still a very few number of regarding `lat` and `lng`, around 0.1% of the total. We also have missing values on the field `population` which will not tackle for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b93JTqgJo920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip              0\n",
       "lat            579\n",
       "lng            579\n",
       "city             0\n",
       "state_id         0\n",
       "state_name       0\n",
       "population    8583\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc0kLUgxo923"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00601</td>\n",
       "      <td>18.1800</td>\n",
       "      <td>-66.7522</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>18570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00602</td>\n",
       "      <td>18.3607</td>\n",
       "      <td>-67.1752</td>\n",
       "      <td>Aguada</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00603</td>\n",
       "      <td>18.4544</td>\n",
       "      <td>-67.1220</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>54689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00604</td>\n",
       "      <td>18.5006</td>\n",
       "      <td>-67.1359</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00605</td>\n",
       "      <td>18.4587</td>\n",
       "      <td>-67.1475</td>\n",
       "      <td>Aguadilla</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zip      lat      lng       city state_id   state_name  population\n",
       "2  00601  18.1800 -66.7522   Adjuntas       PR  Puerto Rico     18570.0\n",
       "3  00602  18.3607 -67.1752     Aguada       PR  Puerto Rico     41520.0\n",
       "4  00603  18.4544 -67.1220  Aguadilla       PR  Puerto Rico     54689.0\n",
       "5  00604  18.5006 -67.1359  Aguadilla       PR  Puerto Rico         NaN\n",
       "6  00605  18.4587 -67.1475  Aguadilla       PR  Puerto Rico         NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_df[zip_df['state_id'] == 'PR'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiOyh4kro927"
   },
   "source": [
    "### Scrapping EWG Tap Water database\n",
    "Request format to gather the initial information about a zip code is as follows:\n",
    "```\n",
    "https://www.ewg.org/tapwater/search-results.php?zip5=ZIP_CODE&searchtype=zip\n",
    "```\n",
    "\n",
    "#### Handling missing data \n",
    "Checking some of the zip codes in the dataframe it seems they're not present in the EWG Tap Water Database, in particular, those referring to __Puerto Rico__ are missing. Therefore, we need to plan to tackle the eventuality that there are no results for a specific zip code.\n",
    "\n",
    "By inspecting the source code of the resulting error page we would look for:\n",
    "\n",
    "```HTML\n",
    "<h2>No systems found that match your search</h2>\n",
    "```\n",
    "\n",
    "As search can also be performe by selecting a state from a list we can see that the only states which can be selected are the following ones: \n",
    "```\n",
    "Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, District Of Columbia, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin and Wyoming\n",
    "```\n",
    "\n",
    "Apparently there is no information on the rest of the states included in this zip database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oj0CjGyIo928"
   },
   "outputs": [],
   "source": [
    "valid_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', \n",
    "    'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', \n",
    "    'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', \n",
    "    'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', \n",
    "    'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', \n",
    "    'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', \n",
    "    'West Virginia', 'Wisconsin', 'Wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfmTj9ivo92_"
   },
   "source": [
    "We can check how many rows do we have for each of the `valid_states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmy0TmWpo93A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 811\n",
      "Alaska 273\n",
      "Arizona 524\n",
      "Arkansas 704\n",
      "California 2589\n",
      "Colorado 643\n",
      "Connecticut 425\n",
      "Delaware 96\n",
      "District of Columbia 291\n",
      "Florida 1472\n",
      "Georgia 951\n",
      "Hawaii 137\n",
      "Idaho 319\n",
      "Illinois 1569\n",
      "Indiana 957\n",
      "Iowa 1055\n",
      "Kansas 747\n",
      "Kentucky 945\n",
      "Louisiana 719\n",
      "Maine 485\n",
      "Maryland 603\n",
      "Massachusetts 681\n",
      "Michigan 1158\n",
      "Minnesota 963\n",
      "Mississippi 531\n",
      "Missouri 1155\n",
      "Montana 404\n",
      "Nebraska 617\n",
      "Nevada 253\n",
      "New Hampshire 281\n",
      "New Jersey 722\n",
      "New Mexico 427\n",
      "New York 2149\n",
      "North Carolina 1080\n",
      "North Dakota 407\n",
      "Ohio 1415\n",
      "Oklahoma 763\n",
      "Oregon 481\n",
      "Pennsylvania 2174\n",
      "Rhode Island 90\n",
      "South Carolina 534\n",
      "South Dakota 385\n",
      "Tennessee 785\n",
      "Texas 2595\n",
      "Utah 344\n",
      "Vermont 308\n",
      "Virginia 1214\n",
      "Washington 715\n",
      "West Virginia 851\n",
      "Wisconsin 882\n",
      "Wyoming 194\n"
     ]
    }
   ],
   "source": [
    "for state in valid_states:\n",
    "    print(state, str((zip_df['state_name'] == state).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZUB6Mi7o93C"
   },
   "source": [
    "Everything looks reasonable, we can proceed to discard all zip codes whose `state_name` is not in the list of the `valid_states`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTgydV2bo93D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of zip codes:  41682\n",
      "Final number of zip codes:  40873\n"
     ]
    }
   ],
   "source": [
    "print('Initial number of zip codes: ', zip_df.shape[0])\n",
    "zip_df = zip_df[zip_df['state_name'].isin(valid_states)]\n",
    "print('Final number of zip codes: ', zip_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JmVrwjpo93G"
   },
   "source": [
    "So, we have discarded 809 zip codes whose state name was not in the list of valid states for the EWG Tap Water Database. This does not prevent that there will not be zip codes for which the webpage doesn't provide results but we've eliminated a source of problems but discarding these zip codes beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmaAMQxUo93H"
   },
   "source": [
    "#### Scrapping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcZRsYoSo93I"
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.ewg.org/tapwater/'\n",
    "SEARCH_URL_START = 'search-results.php?zip5='\n",
    "SEARCH_URL_END = '&searchtype=zip'\n",
    "\n",
    "url = 'https://www.ewg.org/tapwater/search-results.php?zip5=96799&searchtype=zip'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z42xlWp9o93J"
   },
   "source": [
    "#### Error handling getting data\n",
    "Error condition occurs when we can find the following `h2` tag:\n",
    "```html\n",
    "<h2>No systems found that match your search</h2>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9l7_2Lko93K"
   },
   "outputs": [],
   "source": [
    "def got_results_from_url(soup, url):\n",
    "    error = soup.find('h2', text = 'No systems found that match your search')\n",
    "    if (error):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFu5xWLMo93N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_results_from_url(soup, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biERW_kOo93Q"
   },
   "source": [
    "#### Processing valid results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hyv_yR-4o93R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>city</th>\n",
       "      <th>state_id</th>\n",
       "      <th>state_name</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00501</td>\n",
       "      <td>40.8133</td>\n",
       "      <td>-73.0476</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00544</td>\n",
       "      <td>40.8133</td>\n",
       "      <td>-73.0476</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>01001</td>\n",
       "      <td>42.0626</td>\n",
       "      <td>-72.6259</td>\n",
       "      <td>Agawam</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>16769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>01002</td>\n",
       "      <td>42.3749</td>\n",
       "      <td>-72.4621</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>29049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>01003</td>\n",
       "      <td>42.3919</td>\n",
       "      <td>-72.5248</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>10372.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       zip      lat      lng        city state_id     state_name  population\n",
       "0    00501  40.8133 -73.0476  Holtsville       NY       New York         NaN\n",
       "1    00544  40.8133 -73.0476  Holtsville       NY       New York         NaN\n",
       "195  01001  42.0626 -72.6259      Agawam       MA  Massachusetts     16769.0\n",
       "196  01002  42.3749 -72.4621     Amherst       MA  Massachusetts     29049.0\n",
       "197  01003  42.3919 -72.5248     Amherst       MA  Massachusetts     10372.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMgmxjnzo93U"
   },
   "source": [
    "#### 1. Search results processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4EfHLzzo93W"
   },
   "outputs": [],
   "source": [
    "def generate_url_from_zip(zip_value):\n",
    "    return BASE_URL + SEARCH_URL_START + zip_value + SEARCH_URL_END\n",
    "\n",
    "def get_population(people_served_tag):\n",
    "    return int(people_served_tag.replace('Population served:', '').replace(',',''))\n",
    "\n",
    "def get_city(element):\n",
    "    return element.text.split(',')[0].strip()\n",
    "\n",
    "def get_state(element):\n",
    "    print(element.text)\n",
    "    return element.text.split(',')[1].strip()\n",
    "\n",
    "def get_city_and_state(element):\n",
    "    split_element = element.text.split(',')\n",
    "    if len(split_element) == 2:\n",
    "        return split_element[0].strip(), split_element[1].strip()\n",
    "    else:\n",
    "        return split_element[0].strip(), '-'\n",
    "\n",
    "def extract_info_from_row(elements):\n",
    "    row_info = {}\n",
    "    row_info['url'] = BASE_URL + elements[0].find('a')['href']\n",
    "    row_info['utility_name'] = elements[0].text\n",
    "    row_info['city'], row_info['state'] = get_city_and_state(elements[1])\n",
    "    row_info['people_served'] = get_population(elements[2].text)\n",
    "    return row_info\n",
    "\n",
    "def process_results(results, zip_value):\n",
    "    zip_results = []\n",
    "    result_rows = results.find_all('tr')\n",
    "    for row in result_rows:\n",
    "        elements = row.find_all('td')\n",
    "        if elements:\n",
    "            element = extract_info_from_row(elements)\n",
    "            element['zip'] = zip_value\n",
    "            zip_results.append(element)\n",
    "    return zip_results\n",
    "\n",
    "def process_zip(zip_value):\n",
    "    url = generate_url_from_zip(zip_value)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    if got_results_from_url(soup, url):\n",
    "        results = soup.find_all('table', {'class': 'search-results-table'})\n",
    "        # NOTE: there are two search-results-table, first one shows the results for the \n",
    "        # largest utilities serving County, the second one is more complete and includes\n",
    "        # utilities serving the searched zip and the surrounding county\n",
    "        # The process will be applied only to the LARGEST UTILITIES which is the first \n",
    "        # result\n",
    "        return process_results(results[0], zip_value)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRPuHyiEo93Y"
   },
   "outputs": [],
   "source": [
    "zip_results = process_zip('00501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SewNwbFo93b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.ewg.org/tapwater/system.php?pws=NY5110526',\n",
       "  'utility_name': 'Suffolk County Water Authority',\n",
       "  'city': 'Hauppauge',\n",
       "  'state': 'NY',\n",
       "  'people_served': 1137108,\n",
       "  'zip': '00501'},\n",
       " {'url': 'https://www.ewg.org/tapwater/system.php?pws=NY5103263',\n",
       "  'utility_name': 'South Huntington Water Department',\n",
       "  'city': 'South Huntington',\n",
       "  'state': 'NY',\n",
       "  'people_served': 81760,\n",
       "  'zip': '00501'},\n",
       " {'url': 'https://www.ewg.org/tapwater/system.php?pws=NY5103271',\n",
       "  'utility_name': 'Greenlawn WD',\n",
       "  'city': 'Greenlawn',\n",
       "  'state': 'NY',\n",
       "  'people_served': 42000,\n",
       "  'zip': '00501'},\n",
       " {'url': 'https://www.ewg.org/tapwater/system.php?pws=NY5103705',\n",
       "  'utility_name': 'Riverhead WD',\n",
       "  'city': 'Riverhead',\n",
       "  'state': 'NY',\n",
       "  'people_served': 37050,\n",
       "  'zip': '00501'},\n",
       " {'url': 'https://www.ewg.org/tapwater/system.php?pws=NY5103276',\n",
       "  'utility_name': 'Dix Hills Water District',\n",
       "  'city': 'Huntington',\n",
       "  'state': 'NY',\n",
       "  'people_served': 34522,\n",
       "  'zip': '00501'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50MDYHvDo93e"
   },
   "source": [
    "#### 2. Processing each utility name to gather information about contaminants\n",
    "The information we are looking for is in the following HTML tags:\n",
    "```html\n",
    "<ul class=\"contaminants-list\" id=\"contams_above_hbl\">\n",
    "```\n",
    "```html\n",
    "<ul class=\"contaminants-list\" id=\"contams_other\">\n",
    "```\n",
    "The first one includes _\"chemicals detected in 2015 for which annual utility averages exceeded an EWG-selected health guideline established by a federal or state public health authority; chemicals detected under the EPA's Unregulated Contaminant Monitoring Rule (UCMR 3) program in 2013 to 2015, for which annual utility averages exceeded a health guideline established by a federal or state public health authority; perfluorinated chemicals.\"_\n",
    "\n",
    "The second section includes _\"chemicals detected under the EPA's Unregulated Contaminant Monitoring Rule (UCMR 3) program in 2013 to 2015, for which annual utility averages were lower than an EWG-selected health guideline established by a federal or state public health authority.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5rvW2klo93e"
   },
   "outputs": [],
   "source": [
    "def get_contaminants(soup, contaminant_type):\n",
    "    section = soup.find('ul', {'class': 'contaminants-list', 'id': contaminant_type})\n",
    "    contaminants_type = section.find_all('div', {'class': 'contaminant-name'})\n",
    "    contaminants = []\n",
    "    for contaminant in contaminants_type:\n",
    "        contaminants.append(contaminant.find('h3').text)\n",
    "    return contaminants\n",
    "\n",
    "def get_contaminants_above_hbl(soup):\n",
    "    return get_contaminants(soup, 'contams_above_hbl')\n",
    "\n",
    "def get_contaminants_other(soup):\n",
    "    return get_contaminants(soup, 'contams_other')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5umx9-yo93i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,3-Trichloropropane', 'Chromium (hexavalent)', 'Perfluorinated chemicals']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.ewg.org/tapwater/system.php?pws=NY5110526'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "get_contaminants_above_hbl(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unOM0Xk6o93k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1-Dichloroethane',\n",
       " '1,4-Dioxane',\n",
       " 'Chlorate',\n",
       " 'Chlorodifluoromethane',\n",
       " 'Chromium (total)',\n",
       " 'Cobalt',\n",
       " 'Molybdenum',\n",
       " 'Strontium',\n",
       " 'Vanadium']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_contaminants_other(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNkyVQh_o93m"
   },
   "source": [
    "### 3. Try the full process on a subset of the dataframe\n",
    "Let's try to apply the full process to small number of zip codes in the dataset selected randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QhRALfSo93n"
   },
   "outputs": [],
   "source": [
    "zip_df_small = zip_df.sample(3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrTXXw6Qo93o"
   },
   "outputs": [],
   "source": [
    "def scrap_ewg_tap_water_database(df):\n",
    "    data = []\n",
    "    \n",
    "    # Step 1: get information about the utilities in each zip code    \n",
    "    for zip_code in df['zip']:\n",
    "        utilities = process_zip(zip_code)\n",
    "        data = data + utilities\n",
    "        \n",
    "    # Step 2: for each utility obtain the contaminants\n",
    "    for utility in data:\n",
    "        r = requests.get(utility['url'])\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        print('Getting contaminants from: ', utility['url'])\n",
    "        utility['contaminants_above_hbl'] = get_contaminants_above_hbl(soup)\n",
    "        utility['contaminants_other'] = get_contaminants_other(soup)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EB_sm-UZo93r"
   },
   "outputs": [],
   "source": [
    "ewg_tap_water = scrap_ewg_tap_water_database(zip_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTuc5yWso93v"
   },
   "outputs": [],
   "source": [
    "ewg_tap_water_df = pd.DataFrame(ewg_tap_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEP1cSWko93y"
   },
   "outputs": [],
   "source": [
    "ewg_tap_water_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yESYcDvAo934"
   },
   "outputs": [],
   "source": [
    "for contaminant in ewg_tap_water_df['contaminants_other']:\n",
    "    print(contaminant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBUssj7To937"
   },
   "source": [
    "### 4. Adjusting the process\n",
    "Looking at the results of this data sample we can appreciate to things: \n",
    "- First, some of the state date is missing, we could fill it out using the zip database which is complete and omit the information scrap from the website\n",
    "- Second, the website encodes some information using the same tags as the ones used for contaminants which should be cleaned up e.g. _'The following chemicals were detected by Tell City Water Department, a supplier of water to Troy Township Water Association'_; we could filter this information by checking those contaminants which are longer than a specific length e.g. > 80 characters\n",
    "\n",
    "Let's implement these two changes and put all important source code together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: the scrapping process takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlq9Fq7lo937"
   },
   "outputs": [],
   "source": [
    "def generate_url_from_zip(zip_value):\n",
    "    return BASE_URL + SEARCH_URL_START + zip_value + SEARCH_URL_END\n",
    "\n",
    "def get_population(people_served_tag):\n",
    "    return int(people_served_tag.replace('Population served:', '').replace(',',''))\n",
    "\n",
    "def get_city(element):\n",
    "    return element.text.split(',')[0].strip()\n",
    "\n",
    "def extract_info_from_row(elements):\n",
    "    row_info = {}\n",
    "    row_info['url'] = BASE_URL + elements[0].find('a')['href']\n",
    "    row_info['utility_name'] = elements[0].text\n",
    "    row_info['city'] = get_city(elements[1])\n",
    "    row_info['people_served'] = get_population(elements[2].text)\n",
    "    return row_info\n",
    "\n",
    "def process_results(results, zip_value, state_id):\n",
    "    zip_results = []\n",
    "    result_rows = results.find_all('tr')\n",
    "    for row in result_rows:\n",
    "        elements = row.find_all('td')\n",
    "        if elements:\n",
    "            element = extract_info_from_row(elements)\n",
    "            element['zip'] = zip_value\n",
    "            element['state'] = state_id\n",
    "            zip_results.append(element)\n",
    "    return zip_results\n",
    "\n",
    "def process_zip(zip_value, state_id):\n",
    "    url = generate_url_from_zip(zip_value)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    if got_results_from_url(soup, url):\n",
    "        results = soup.find_all('table', {'class': 'search-results-table'})\n",
    "        # NOTE: there are two search-results-table, first one shows the results for the \n",
    "        # largest utilities serving County, the second one is more complete and includes\n",
    "        # utilities serving the searched zip and the surrounding county\n",
    "        # The process will be applied only to the LARGEST UTILITIES which is the first \n",
    "        # result\n",
    "        return process_results(results[0], zip_value, state_id)\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def get_contaminants(soup, contaminant_type):\n",
    "    section = soup.find('ul', {'class': 'contaminants-list', 'id': contaminant_type})\n",
    "    if section:\n",
    "        contaminants_type = section.find_all('div', {'class': 'contaminant-name'})\n",
    "        contaminants = []\n",
    "        for contaminant in contaminants_type:\n",
    "            contaminant_name = contaminant.find('h3').text\n",
    "            if len(contaminant_name) < 80:\n",
    "                contaminants.append(contaminant.find('h3').text)\n",
    "        return contaminants\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def get_contaminants_above_hbl(soup):\n",
    "    return get_contaminants(soup, 'contams_above_hbl')\n",
    "\n",
    "def get_contaminants_other(soup):\n",
    "    return get_contaminants(soup, 'contams_other')  \n",
    "\n",
    "def get_all_contaminants(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    contaminants_above_hbl = get_contaminants_above_hbl(soup)\n",
    "    contaminants_other = get_contaminants_other(soup)\n",
    "    \n",
    "    return (contaminants_above_hbl, contaminants_other)\n",
    "    \n",
    "def scrap_contaminants_from_df(df):\n",
    "    contaminants_rows = []\n",
    "   \n",
    "    status = 0\n",
    "    bar = progressbar.ProgressBar(max_value=df.shape[0])\n",
    "    \n",
    "    for index, utility in df.iterrows():\n",
    "        # percentage of completion\n",
    "        bar.update(status)        \n",
    "        status = status + 1\n",
    "        \n",
    "        r = requests.get(utility['url'])\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        row = {}\n",
    "        row['zip'] = utility['zip']\n",
    "        row['city'] = utility['city']        \n",
    "        row['contaminants_above_hbl'] = get_contaminants_above_hbl(soup)\n",
    "        row['contaminants_other'] = get_contaminants_other(soup)\n",
    "        contaminants_rows.append(row)\n",
    "    bar.finish()\n",
    "    \n",
    "    return contaminants_rows\n",
    "    \n",
    "def scrap_ewg_tap_water_database(df):\n",
    "    data = []\n",
    "       \n",
    "    status = 0\n",
    "    bar = progressbar.ProgressBar(max_value=df.shape[0])\n",
    "    \n",
    "    # Step 1: get information about the utilities in each zip code    \n",
    "    for index, row in df.iterrows():\n",
    "        # percentage of completion\n",
    "        bar.update(status)        \n",
    "        status = status + 1\n",
    "        \n",
    "        utilities = process_zip(row['zip'], row['state_id'])\n",
    "        data = data + utilities\n",
    "    bar.finish()\n",
    "    \n",
    "    # Let's save this to a CSV just in case the second process does not work\n",
    "    utilities_df = pd.DataFrame(data)\n",
    "    utilities_df.to_csv('utilities.csv', index=False)\n",
    "        \n",
    "    # Step 2: for each utility obtain the contaminants\n",
    "    status = 0\n",
    "    bar = progressbar.ProgressBar(max_value=len(data))\n",
    "    for utility in data:\n",
    "        # percentage of completion\n",
    "        bar.update(status)        \n",
    "        status = status + 1\n",
    "        \n",
    "        r = requests.get(utility['url'])\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        utility['contaminants_above_hbl'] = get_contaminants_above_hbl(soup)\n",
    "        utility['contaminants_other'] = get_contaminants_other(soup)\n",
    "    bar.finish()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFLQ8Vano94A"
   },
   "source": [
    "### 5. Scrap full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3sscdP3o94A"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT NOTE: THIS PROCESS TAKES A LONG TIME - UNCOMMENT IF YOU WANT TO PROCEED\n",
    "# ewg_tap_water = scrap_ewg_tap_water_database(zip_df)\n",
    "# ewg_tap_water_df = pd.DataFrame(ewg_tap_water)\n",
    "# ewg_tap_water_df.to_csv('ewg.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vmaAMQxUo93H",
    "z42xlWp9o93J",
    "biERW_kOo93Q",
    "dMgmxjnzo93U",
    "50MDYHvDo93e"
   ],
   "name": "EWG.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
